{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News post mining for show HN and Ask HN posts\n",
    "\n",
    "Hacker News is a site where user-submitted stories (known as \"posts\") are voted and commented upon.\n",
    "\n",
    "We have a data set for the posts of hacker newÿ≥. But note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. you can download the data set from [here](https://www.kaggle.com/hacker-news/hacker-news-posts/home) \n",
    "\n",
    "We have to main questions \n",
    "\n",
    "1- Ask HN or Show HN posts receive more comments on average?\n",
    "2- The posts that created in specific time do they receive more comments on average?\n",
    "\n",
    "## Summary of results:\n",
    "\n",
    "3 AM is the best time to post a Ask HN post to get more comments and 11 AM to 1PM is the best time to post a Show HN post. \n",
    "\n",
    "## opening the data set\n",
    "\n",
    "\n",
    "We start with opening and reading hacker_news.csv and showing first five rows of it.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']] [['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "def open_file(file_name):\n",
    "    opened_file = open(file_name, encoding = 'utf8')\n",
    "    read_file = reader(opened_file)\n",
    "    dataset = list(read_file)\n",
    "    return dataset[1:], dataset[0:1]\n",
    "\n",
    "hn, hn_header = open_file(\"hacker_news.csv\")\n",
    "\n",
    "print(hn_header, hn[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing the data set\n",
    "\n",
    "We divide the data set to three main groups \n",
    "\n",
    "1- Ask HN posts\n",
    "2- Show HN posts\n",
    "3- Oher posts\n",
    "\n",
    "We put the rows with the title starting with Ask HN to ask_posts list, with Show HN to show_posts list and the others to other_posts list. Also we displayed the number of rows and some rows for sub data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n",
      "\n",
      "\n",
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', 2], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', 1]]\n",
      "\n",
      "\n",
      "[['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36'], ['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(ask_posts[0:2])\n",
    "print(\"\\n\")\n",
    "print(show_posts[0:2])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average comments for ask and show posts\n",
    "\n",
    "In this section we are calculating average number of comments for per post for ask and show sub data sets\n",
    "\n",
    "Number of comments for each row is stored in the index 4\n",
    "We iterate over each sub data sets and calculate total number of comments for each sub data set then divide it to lengths of each sub data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask posts average comments is equal to 10.393478498741656\n",
      "Show posts average comments is equal to 4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(\"Ask posts average comments is equal to {}\".format(avg_ask_comments))\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(\"Show posts average comments is equal to {}\".format(avg_show_comments))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the average comments for ask posts is equal to 10.39 and for show posts is equal to 4.88. Therefore ask posts receives more comments on average\n",
    "\n",
    "Because of this we will focuses the remaining analysis just on these posts and we want to determine if ask posts created at a certain time are more likely to attract comments.\n",
    "\n",
    "In the code blow we convers the value of 'created_at' column for ask_posts sub data set to datetime.datetime object and we use hour method to only store hours for this column because we want to calculate post and comments for each hour of the day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "for row in ask_posts:\n",
    "    date_time = row[-1]\n",
    "    date_time = dt.datetime.strptime(date_time, \"%m/%d/%Y %H:%M\")\n",
    "    time_hour = date_time.hour\n",
    "    row[-1] = time_hour\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency tables \n",
    " In this part we create frequency table for number of posts for each hours a day and for number of comments for each hours a day.\n",
    " \n",
    " Keys for both of dictionaries are day's hours and values are number of posts for 'freq_hour_post' and number of comments for 'freq_hour_comments'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 269, 1: 282, 22: 383, 21: 518, 19: 552, 17: 587, 15: 646, 14: 513, 13: 444, 11: 312, 10: 282, 9: 222, 7: 226, 3: 271, 23: 343, 20: 510, 16: 579, 8: 257, 0: 301, 18: 614, 12: 342, 4: 243, 6: 234, 5: 209}\n",
      "\n",
      "\n",
      "{2: 2996, 1: 2089, 22: 3372, 21: 4500, 19: 3954, 17: 5547, 15: 18525, 14: 4972, 13: 7245, 11: 2797, 10: 3013, 9: 1477, 7: 1585, 3: 2154, 23: 2297, 20: 4462, 16: 4466, 8: 2362, 0: 2277, 18: 4877, 12: 4234, 4: 2360, 6: 1587, 5: 1838}\n"
     ]
    }
   ],
   "source": [
    "freq_hour_post = {}\n",
    "freq_hour_comments = {}\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    hour = row[-1]\n",
    "    if hour in freq_hour_post:\n",
    "        freq_hour_post[hour] += 1\n",
    "    else:\n",
    "        freq_hour_post[hour] = 1\n",
    "        \n",
    "    if hour in freq_hour_comments:\n",
    "        freq_hour_comments[hour] += num_comments\n",
    "    else:\n",
    "        freq_hour_comments[hour] = num_comments\n",
    "\n",
    "print(freq_hour_post)\n",
    "print(\"\\n\")\n",
    "print(freq_hour_comments)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating frequency tables now is the time to calculate average number of comments per post for each hours of the day.\n",
    "\n",
    "We only need to divide the values of the 'freq_hour_comments' dictionary to values of the 'freq_hour_post' one by one for each corresponding key which are the day's hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 11.137546468401487], [1, 7.407801418439717], [22, 8.804177545691905], [21, 8.687258687258687], [19, 7.163043478260869], [17, 9.449744463373083], [15, 28.676470588235293], [14, 9.692007797270955], [13, 16.31756756756757], [11, 8.96474358974359], [10, 10.684397163120567], [9, 6.653153153153153], [7, 7.013274336283186], [3, 7.948339483394834], [23, 6.696793002915452], [20, 8.749019607843136], [16, 7.713298791018998], [8, 9.190661478599221], [0, 7.5647840531561465], [18, 7.94299674267101], [12, 12.380116959064328], [4, 9.7119341563786], [6, 6.782051282051282], [5, 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "averge_comments_hour = []\n",
    "\n",
    "for hour in freq_hour_comments:\n",
    "    averge_comments = freq_hour_comments[hour] / freq_hour_post[hour]\n",
    "    averge_comments_hour.append([hour, averge_comments])\n",
    "    \n",
    "print(averge_comments_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display better view of the above results we first changes the columns of the averge_comments_hour. In this case we have hours at first column then the corresponding average in the next column. With this we can use sorted () faction to sort this list to have a better view of our results.\n",
    "\n",
    "After that by using datetime.strptime method we create time object for each hours column then by using strftime method we transform it to our desired string format which is for example: 14:00.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 hourse for ask posts comments average\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_averge_comments_hour = []\n",
    "\n",
    "for row in averge_comments_hour:\n",
    "    date_time_p = dt.datetime.strptime(str(row[0]), \"%H\")\n",
    "    time_string = date_time_p.strftime(\"%H:%M\")\n",
    "    \n",
    "    swap_averge_comments_hour.append([row[1], time_string])\n",
    "    \n",
    "#print(swap_averge_comments_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_averge_comments_hour, reverse = True)\n",
    "\n",
    "print(\"Top 6 hourse for ask posts comments average\")\n",
    "\n",
    "template = \"{time}: {average:.2f} average comments per post\"\n",
    "\n",
    "for i in range(5):\n",
    "    print(template.format(time = sorted_swap[i][1], average = sorted_swap[i][0] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see clearly in the results above. The ask posts which posted at 3 PM have the most comments and after that is 1 PM post. Therefore if we want to have the most comments for our Ask HN post we need to post it in 3PM Eastern Time in the US (based on the data set [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home).\n",
    "\n",
    "## Analysis the average points for ask and show posts\n",
    "\n",
    "In this section we will repeat somehow previous works but this time for average points for each hours a day and each two types of posts Ask HN and Show HN.\n",
    "\n",
    "First we will calculate average points for Ask and Show HN posts as in blew code. The index for points in the dataset is 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask posts average points is equal to 11.31174089068826\n",
      "Show posts average points is equal to 14.843571569206537\n"
     ]
    }
   ],
   "source": [
    "total_ask_points = 0\n",
    "total_show_points = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_points = int(row[3])\n",
    "    total_ask_points += num_points\n",
    "    \n",
    "avg_ask_points = total_ask_points / len(ask_posts)\n",
    "print(\"Ask posts average points is equal to {}\".format(avg_ask_points))\n",
    "\n",
    "for row in show_posts:\n",
    "    num_points = int(row[3])\n",
    "    total_show_points += num_points\n",
    "    \n",
    "avg_show_points = total_show_points / len(show_posts)\n",
    "print(\"Show posts average points is equal to {}\".format(avg_show_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it's clear average points for Show HN posts is higher than ask posts then we are going to calculate average points for each days hour for Show HN data set. We will reaped previous steps for comments average. Therefore we will not explain every step explicitly (just the heading)\n",
    "\n",
    "#### Transforming 'created_at' column for show hn sub data set to datetime hour object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in show_posts:\n",
    "    date_time = row[-1]\n",
    "    date_time = dt.datetime.strptime(date_time, \"%m/%d/%Y %H:%M\")\n",
    "    time_hour = date_time.hour\n",
    "    row[-1] = time_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating frequency tables for number of posts and points for each hours a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 276, 23: 319, 20: 525, 19: 556, 18: 656, 16: 801, 14: 696, 10: 323, 9: 302, 8: 316, 6: 192, 3: 206, 21: 430, 17: 761, 15: 836, 11: 402, 7: 236, 4: 194, 13: 610, 12: 516, 1: 247, 22: 377, 2: 209, 5: 172}\n",
      "\n",
      "\n",
      "{0: 4291, 23: 5060, 20: 6948, 19: 8928, 18: 9935, 16: 11487, 14: 10503, 10: 4303, 9: 3762, 8: 4640, 6: 3071, 3: 2168, 21: 5990, 17: 10563, 15: 11657, 11: 7742, 7: 3303, 4: 2707, 13: 10381, 12: 10787, 1: 2931, 22: 5026, 2: 2764, 5: 1834}\n"
     ]
    }
   ],
   "source": [
    "freq_hour_post_show = {}\n",
    "freq_hour_points = {}\n",
    "\n",
    "for row in show_posts:\n",
    "    num_points = int(row[3])\n",
    "    hour = row[-1]\n",
    "    if hour in freq_hour_post_show:\n",
    "        freq_hour_post_show[hour] += 1\n",
    "    else:\n",
    "        freq_hour_post_show[hour] = 1\n",
    "        \n",
    "    if hour in freq_hour_points:\n",
    "        freq_hour_points[hour] += num_points\n",
    "    else:\n",
    "        freq_hour_points[hour] = num_points\n",
    "\n",
    "print(freq_hour_post_show)\n",
    "print(\"\\n\")\n",
    "print(freq_hour_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average points per post for each hours a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 15.547101449275363], [23, 15.862068965517242], [20, 13.234285714285715], [19, 16.057553956834532], [18, 15.144817073170731], [16, 14.340823970037453], [14, 15.09051724137931], [10, 13.321981424148607], [9, 12.456953642384105], [8, 14.683544303797468], [6, 15.994791666666666], [3, 10.524271844660195], [21, 13.930232558139535], [17, 13.88042049934297], [15, 13.94377990430622], [11, 19.258706467661693], [7, 13.995762711864407], [4, 13.95360824742268], [13, 17.018032786885247], [12, 20.905038759689923], [1, 11.866396761133604], [22, 13.331564986737401], [2, 13.224880382775119], [5, 10.662790697674419]]\n"
     ]
    }
   ],
   "source": [
    "averge_points_hour = []\n",
    "\n",
    "for hour in freq_hour_points:\n",
    "    averge_points = freq_hour_points[hour] / freq_hour_post_show[hour]\n",
    "    averge_points_hour.append([hour, averge_points])\n",
    "    \n",
    "print(averge_points_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifing the data to have better view of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 hourse for show posts points average\n",
      "12:00: 20.91 average points per post\n",
      "11:00: 19.26 average points per post\n",
      "13:00: 17.02 average points per post\n",
      "19:00: 16.06 average points per post\n",
      "06:00: 15.99 average points per post\n"
     ]
    }
   ],
   "source": [
    "swap_averge_points_hour = []\n",
    "\n",
    "for row in averge_points_hour:\n",
    "    date_time_p = dt.datetime.strptime(str(row[0]), \"%H\")\n",
    "    time_string = date_time_p.strftime(\"%H:%M\")\n",
    "    \n",
    "    swap_averge_points_hour.append([row[1], time_string])\n",
    "    \n",
    "\n",
    "sorted_swap_points = sorted(swap_averge_points_hour, reverse = True)\n",
    "\n",
    "\n",
    "print(\"Top 6 hourse for show posts points average\")\n",
    "\n",
    "template_2 = \"{time}: {points:.2f} average points per post\"\n",
    "\n",
    "for i in range(5):\n",
    "    print(template_2.format(time = sorted_swap_points[i][1], points = sorted_swap_points[i][0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above average number of points per post for 12:00 is equal to 20.91 following by 11 AM with 19.26 and 1PM with 17.02 average points per posts. This shows us the best time to post a ask show post to get a higher points is 12:00 Eastern Time in the US (based on the data set [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home).\n",
    "\n",
    "But because average points result for 12:00, 11:00 and 13:00 is not so different we can conclude that we can post our Show HN post from 11AM to 1PM.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this project we analyzed the Hacker news web site data set. We calculated the average number of comments per post for each hour's day for Ask HN posts and average points per posts for each hours a day for Show HN posts. The result was if we want o to posts Ask HN posts and get more comments the best time is 3 PM. But if we want to post Show HN post to get more points the best time is from 11AM to 1PM.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
